RAW_DATADIR = "inputs/raw"
SAMPLES = ["2412_INPUT_1", "2412_INPUT_2", "2412_INPUT_3",
            "2412_YRA1IP_1", "2412_YRA1IP_2", "2412_YRA1IP_3","2527_INPUT_1", "2527_INPUT_2", "2527_INPUT_3",
            "2527_YRA1IP_1", "2527_YRA1IP_2", "2527_YRA1IP_3","3593_INPUT_1", "3593_INPUT_2", "3593_INPUT_3",
            "3593_YRA1IP_1", "3593_YRA1IP_2", "3593_YRA1IP_3","3605_INPUT_1", "3605_INPUT_2", "3605_INPUT_3",
            "3605_YRA1IP_1", "3605_YRA1IP_2", "3605_YRA1IP_3","3771_INPUT_1", "3771_INPUT_2", "3771_INPUT_3",
            "3771_YRA1IP_1", "3771_YRA1IP_2", "3771_YRA1IP_3"]

rule all:
    input:
       "outputs/counts/raw_counts.csv",
       "outputs/counts/Ribo_counts.csv"

rule umi_extract:
    input: "inputs/raw/{sample}_TAG0183_R1.fastq.gz"
    output: "outputs/umi_extract/{sample}.fq.gz"
    conda: "envs/umitools.yml"
    shell:'''
    umi_tools extract  --extract-method=regex --bc-pattern='(?P<umi_1>.{{6}})(?P<discard_1>TATA)(?P<discard_2>.{{12}})' --log={output}.log --stdin={input} --stdout {output}
    '''

rule fastqc:
    input: "outputs/umi_extract/{sample}.fq.gz"
    output: "outputs/fastqc_umi/{sample}_fastq.html"
    params: outdir = "outputs/fastqc_umi"
    conda: "envs/fastqc.yml"
    shell:'''
    fastqc -o {params.outdir} -t 8 --nogroup {input}
    '''

rule bbduk_trim:
    input:
        reads = "outputs/umi_extract/{sample}.fq.gz",
        polya = "inputs/polya.fa",
        adapters = "inputs/truseq_rna.fa",
    output: "outputs/bbduk/{sample}.fq"
    conda: "envs/bbmap.yml"
    shell:'''
    bbduk.sh in={input.reads} out={output} ref={input.polya},{input.adapters} \
    k=13 ktrim=r useshortkmers=t mink=5 qtrim=r trimq=10 minlength=20
    '''

rule bbsplit_rRNA:
    input:
        reads = "outputs/bbduk/{sample}.fq",
        rRNA = "inputs/ribokmers.fa"
    output:
        clean = "outputs/bbsplit/{sample}_clean.fq",
        #ribo = "outputs/bbsplit/{sample}_ribokmers.fq"
    params: basename = "outputs/bbsplit/{sample}_%.fq"
    conda: "envs/bbmap.yml"
    shell: '''
    bbsplit.sh in={input.reads} ref={input.rRNA} basename={params.basename} outu={output.clean}
    '''

rule fastqc_trim:
    input: "outputs/bbduk/{sample}.fq"
    output: "outputs/fastqc_trim/{sample}_fastq.html"
    params: outdir = "outputs/fastqc_trim"
    conda: "envs/fastqc.yml"
    shell:'''
    fastqc -o {params.outdir} -t 8 --nogroup {input}
    '''

rule download_genome:
    output: 'inputs/genome/GCF_000146045.2_R64_genomic.fna.gz'
    shell:'''
    wget -O {output} https://ftp.ncbi.nlm.nih.gov/genomes/refseq/fungi/Saccharomyces_cerevisiae/latest_assembly_versions/GCF_000146045.2_R64/GCF_000146045.2_R64_genomic.fna.gz
    '''

rule decompress_genome:
    input: 'inputs/genome/GCF_000146045.2_R64_genomic.fna.gz'
    output: 'inputs/genome/GCF_000146045.2_R64_genomic.fna'
    shell: "gunzip {input}"

rule download_gtf:
    output: 'inputs/genome/GCF_000146045.2_R64_genomic.gtf.gz'
    shell:'''
    wget -O {output} https://ftp.ncbi.nlm.nih.gov/genomes/refseq/fungi/Saccharomyces_cerevisiae/latest_assembly_versions/GCF_000146045.2_R64/GCF_000146045.2_R64_genomic.gtf.gz
    '''

rule decompress_gtf:
    input: 'inputs/genome/GCF_000146045.2_R64_genomic.gtf.gz'
    output: 'inputs/genome/GCF_000146045.2_R64_genomic.gtf'
    shell: "gunzip {input}"

rule star_index_genome:
    input:
        genome = 'inputs/genome/GCF_000146045.2_R64_genomic.fna',
        gtf = 'inputs/genome/GCF_000146045.2_R64_genomic.gtf'
    params: input_dir = 'inputs/genome'
    conda: 'envs/star.yml'
    output: 'inputs/genome/SAindex'
    shell:'''
    STAR --runThreadN 1 --runMode genomeGenerate --genomeDir {params.input_dir} \
         --genomeFastaFiles {input.genome} --sjdbGTFfile {input.gtf} --sjdbOverhang  99
    '''


##################
#  Sample counts #
##################

rule star_align:
    #v2.7.10a
    input:
        reads = "outputs/bbsplit/{sample}_clean.fq",
        genome_index = 'inputs/genome/SAindex'
    output: 'outputs/star/{sample}Aligned.sortedByCoord.out.bam'
    params:
        out_prefix = lambda wildcards: 'outputs/star/' + wildcards.sample,
        genome_dir = 'inputs/genome'
    conda: 'envs/star.yml'
    shell:'''
    STAR --runThreadN 2 --genomeDir {params.genome_dir}      \
        --readFilesIn {input.reads} --outFilterType BySJout  \
        --outFilterMultimapNmax 20 --alignSJoverhangMin 8    \
        --alignSJDBoverhangMin 1 --outFilterMismatchNmax 999 \
        --outFilterMismatchNoverLmax 0.6 --alignIntronMin 20 \
        --alignIntronMax 1000000 --alignMatesGapMax 1000000  \
        --outSAMattributes NH HI NM MD --outSAMtype BAM      \
        SortedByCoordinate --outFileNamePrefix {params.out_prefix}
    '''

rule index_bam:
    input: 'outputs/star/{sample}Aligned.sortedByCoord.out.bam'
    output: 'outputs/star/{sample}Aligned.sortedByCoord.out.bam.bai'
    conda: 'envs/samtools.yml'
    shell:'''
    samtools index {input}
    '''

rule dedup_UMI:
    input:
        bam = 'outputs/star/{sample}Aligned.sortedByCoord.out.bam',
        bai = 'outputs/star/{sample}Aligned.sortedByCoord.out.bam.bai'
    output: 'outputs/dedup/{sample}.dedup.bam'
    conda: 'envs/umitools.yml'
    shell:'''
    umi_tools dedup -I {input.bam} --output-stats=deduplicated -S {output}
    '''

rule htseq_count:
    input:
        bam = 'outputs/dedup/{sample}.dedup.bam',
        gtf = 'inputs/genome/GCF_000146045.2_R64_genomic.gtf'
    output: "outputs/htseq/{sample}_readcounts.txt"
    conda: "envs/htseq.yml"
    shell:'''
    htseq-count -m intersection-nonempty -s yes -f bam -r pos {input.bam} {input.gtf} > {output}
    '''

rule make_counts:
    input: expand("outputs/htseq/{sample}_readcounts.txt", sample = SAMPLES)
    output: "outputs/counts/raw_counts.csv"
    conda: "envs/tidyverse.yml"
    script: "scripts/make_raw_counts.R"





##################
#  RiboCounts    #
##################

rule star_align_ribo:
    #v2.7.10a
    input:
        reads = "outputs/bbsplit/{sample}_ribokmers.fq",
        genome_index = 'inputs/genome/SAindex'
    output: 'outputs/Ribo/{sample}Aligned.sortedByCoord.out.bam'
    params:
        out_prefix = lambda wildcards: 'outputs/Ribo/' + wildcards.sample,
        genome_dir = 'inputs/genome'
    conda: 'envs/star.yml'
    shell:'''
    STAR --runThreadN 2 --genomeDir {params.genome_dir}      \
        --readFilesIn {input.reads} --outFilterType BySJout  \
        --outFilterMultimapNmax 20 --alignSJoverhangMin 8    \
        --alignSJDBoverhangMin 1 --outFilterMismatchNmax 999 \
        --outFilterMismatchNoverLmax 0.6 --alignIntronMin 20 \
        --alignIntronMax 1000000 --alignMatesGapMax 1000000  \
        --outSAMattributes NH HI NM MD --outSAMtype BAM      \
        SortedByCoordinate --outFileNamePrefix {params.out_prefix}
    '''

rule index_bam_ribo:
    input: 'outputs/Ribo/{sample}Aligned.sortedByCoord.out.bam'
    output: 'outputs/Ribo/{sample}Aligned.sortedByCoord.out.bam.bai'
    conda: 'envs/samtools.yml'
    shell:'''
    samtools index {input}
    '''

rule dedup_UMI_ribo:
    input:
        bam = 'outputs/Ribo/{sample}Aligned.sortedByCoord.out.bam',
        bai = 'outputs/Ribo/{sample}Aligned.sortedByCoord.out.bam.bai'
    output: 'outputs/Ribo/{sample}.dedup.bam'
    conda: 'envs/umitools.yml'
    shell:'''
    umi_tools dedup -I {input.bam} --output-stats=deduplicated -S {output}
    '''

rule htseq_count_ribo:
    input:
        bam = 'outputs/Ribo/{sample}.dedup.bam',
        gtf = 'inputs/genome/GCF_000146045.2_R64_genomic.gtf'
    output: "outputs/Ribo/{sample}_readcounts.txt"
    conda: "envs/htseq.yml"
    shell:'''
    htseq-count -m intersection-nonempty -s yes -f bam -r pos {input.bam} {input.gtf} > {output}
    '''

rule make_counts_ribo:
    input: expand("outputs/Ribo/{sample}_readcounts.txt", sample = SAMPLES)
    output: "outputs/counts/Ribo_counts.csv"
    conda: "envs/tidyverse.yml"
    script: "scripts/make_raw_counts.R"
